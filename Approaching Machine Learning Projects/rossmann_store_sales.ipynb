{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82375a9d",
   "metadata": {},
   "source": [
    "Let's install and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib plotly seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opendatasets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a734d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size']=14\n",
    "matplotlib.rcParams['figure.figsize']=(10,6)\n",
    "matplotlib.rcParams['figure.facecolor']='#00000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180adad",
   "metadata": {},
   "source": [
    "## Step 1 - Understand Business Requirements & Nature of Data\n",
    "\n",
    "<img src=\"https://i.imgur.com/63XEArk.png\" width=\"640\">\n",
    "\n",
    "\n",
    "Most machine learning models are trained to serve a real-world use case. It's important to understand the business requirements, modeling objectives and the nature of the data available before you start building a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0cd463",
   "metadata": {},
   "source": [
    "### Understanding the Big Picture\n",
    "\n",
    "The first step in any machine learning problem is to read the given documentation, talk to various stakeholders and identify the following:\n",
    "\n",
    "1. What is the business problem you're trying to solve using machine learning?\n",
    "2. Why are we interested in solving this problem? What impact will it have on the business?\n",
    "3. How is this problem solved currently, without any machine learning tools?\n",
    "4. Who will use the results of this model, and how does it fit into other business processes?\n",
    "5. How much historical data do we have, and how was it collected?\n",
    "6. What features does the historical data contain? Does it contain the historical values for what we're trying to predict.\n",
    "7. What are some known issues with the data (data entry errors, missing data, differences in units etc.)\n",
    "8. Can we look at some sample rows from the dataset? How representative are they of the entire dataset.\n",
    "9. Where is the data stored and how will you get access to it?\n",
    "10. ...\n",
    "\n",
    "\n",
    "Gather as much information about the problem as possible, so that you're clear understanding of the objective and feasibility of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f8cbd",
   "metadata": {},
   "source": [
    "### Working with Real World Data\n",
    "\n",
    "Whenever possible, try to work with real world datasets. [Kaggle](https://kaggle.com/datasets) is a great source for real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e060e145",
   "metadata": {},
   "source": [
    "## Step 2 - Classify the problem as supervised/unsupervised & regression/classification\n",
    "\n",
    "<img src=\"https://i.imgur.com/rqt2A7F.png\" width=\"640\">\n",
    "\n",
    "Here's the landscape of machine learning([source](https://medium.datadriveninvestor.com/machine-learning-in-10-minutes-354d83e5922e)):\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/842/1*tlQwBmbL6RkuuFq8OPJofw.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9fb00e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here are the topics in machine learning that we're studying in this course ([source](https://vas3k.com/blog/machine_learning/)): \n",
    "\n",
    "<img src=\"https://i.imgur.com/VbVFAsg.png\" width=\"640\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9eafd",
   "metadata": {},
   "source": [
    "### Loss Functions and Evaluation Metrics\n",
    "\n",
    "Once you have identified the type of problem you're solving, you need to pick an appropriate evaluation metric. Also, depending on the kind of model you train, your model will also use a loss/cost function to optimize during the training process.\n",
    "\n",
    "* **Evaluation metrics** - they're used by humans to evaluate the ML model\n",
    "\n",
    "* **Loss functions** - they're used by computers to optimize the ML model\n",
    "\n",
    "They are often the same (e.g. RMSE for regression problems), but they can be different (e.g. Cross entropy and Accuracy for classification problems).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68265556",
   "metadata": {},
   "source": [
    "## Step 3 - Download, clean & explore the data and create new features\n",
    "\n",
    "<img src=\"https://i.imgur.com/0f7foe7.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a915db",
   "metadata": {},
   "source": [
    "### Downloading Data\n",
    "\n",
    "There may be different sources to get the data:\n",
    "\n",
    "* CSV files\n",
    "* SQL databases\n",
    "* Raw File URLs\n",
    "* Kaggle datasets \n",
    "* Google Drive\n",
    "* Dropbox\n",
    "* etc.\n",
    "\n",
    "Identify the right tool/library to get the data. \n",
    "\n",
    "For the Rossmann Store Sales prediction dataset, we'll use the `opendatasets` library. Make sure to [accept the competition rules](https://www.kaggle.com/c/rossmann-store-sales/rules) before executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download('https://www.kaggle.com/c/rossmann-store-sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('rossmann-store-sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "ross_df=pd.read_csv('./rossmann-store-sales/train.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "ross_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89158050",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df=pd.read_csv('./rossmann-store-sales/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a4afe",
   "metadata": {},
   "source": [
    "We can merge the two data frames to get a richer set of features for each row of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=ross_df.merge(store_df,how='left',on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fd962",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870d0c0",
   "metadata": {},
   "source": [
    "The dataset also contains a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41968ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('rossmann-store-sales/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df=test_df.merge(store_df,how='left',on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ed411",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b5fbf",
   "metadata": {},
   "source": [
    "### Cleaning Data\n",
    "\n",
    "The first step is to check the column data types and identify if there are any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438bc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79908c",
   "metadata": {},
   "source": [
    "It appears that there are no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(merged_df.describe().T,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a8b4b",
   "metadata": {},
   "source": [
    "Let's also parse the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58537ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Date']=pd.to_datetime(merged_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe058c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df['Date']=pd.to_datetime(merged_test_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.Date.min(),merged_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84988",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df.Date.min(),merged_test_df.Date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6cba22",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis and Visualization\n",
    "\n",
    "Objectives of exploratory data analysis:\n",
    "\n",
    "- Study the distributions of individual columns (uniform, normal, exponential)\n",
    "- Detect anomalies or errors in the data (e.g. missing/incorrect values)\n",
    "- Study the relationship of target column with other columns (linear, non-linear etc.)\n",
    "- Gather insights about the problem and the dataset\n",
    "- Come up with ideas for preprocessing and feature engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6a0db",
   "metadata": {},
   "source": [
    "Let's study the distribution of the target \"Sales\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c61d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=merged_df,x='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f51db",
   "metadata": {},
   "source": [
    "Can you explain why the sales are 0 on so many dates? \n",
    "\n",
    "Let's check if this is because the store was closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.Open.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.Sales.value_counts()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb31265",
   "metadata": {},
   "source": [
    "To make our modeling simple, let's simply exclude the dates when the store was closed (we can handle it as a special case while making predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3374c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=merged_df[merged_df.Open==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=merged_df,x='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed658b",
   "metadata": {},
   "source": [
    "Let's explore some other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "temp_df=merged_df.sample(40000)\n",
    "sns.scatterplot(x=temp_df.Sales,y=temp_df.Customers,hue=temp_df.Date.dt.year,alpha=0.8)\n",
    "plt.title('Sales vs Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "temp_df=merged_df.sample(10000)\n",
    "sns.scatterplot(x=temp_df.Store,y=temp_df.Sales,hue=temp_df.Date.dt.year,alpha=0.8)\n",
    "plt.title('Stores Vs Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=merged_df,x='DayOfWeek',y='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ead36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=merged_df,x='Promo',y='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols=['Store',\n",
    "               'DayOfWeek',\n",
    "               'Date',\n",
    "               'Sales',\n",
    "               'Customers',\n",
    "               'Open',\n",
    "               'Promo',\n",
    "               'SchoolHoliday',\n",
    "               'CompetitionDistance',\n",
    "               'CompetitionOpenSinceMonth',\n",
    "               'CompetitionOpenSinceYear',\n",
    "               'Promo2',\n",
    "               'Promo2SinceWeek',\n",
    "               'Promo2SinceYear']\n",
    "correlation_matrix=merged_df[selected_cols].corr()\n",
    "print(correlation_matrix['Sales'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2e1d9",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Feature engineer is the process of creating new features (columns) by transforming/combining existing features or by incorporating data from external sources. \n",
    "\n",
    "\n",
    "For example, here are some features that can be extracted from the \"Date\" column:\n",
    "\n",
    "1. Day of week\n",
    "2. Day or month\n",
    "3. Month\n",
    "4. Year\n",
    "5. Weekend/Weekday\n",
    "6. Month/Quarter End\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Day']=merged_df.Date.dt.day\n",
    "merged_df['Month']=merged_df.Date.dt.month\n",
    "merged_df['Year']=merged_df.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df['Day']=merged_test_df.Date.dt.day\n",
    "merged_test_df['Month']=merged_test_df.Date.dt.month\n",
    "merged_test_df['Year']=merged_test_df.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd722a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=merged_df,x='Year',y='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=merged_df,x='Month',y='Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67416fe",
   "metadata": {},
   "source": [
    "## Step 4 - Create a training/test/validation split and prepare the data for training\n",
    "\n",
    "<img src=\"https://i.imgur.com/XZ9aP10.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f6a23",
   "metadata": {},
   "source": [
    "### Train/Test/Validation Split\n",
    "\n",
    "The data already contains a test set, which contains over one month of data after the end of the training set. We can apply a similar strategy to create a validation set. We'll the last 25% of rows for the validation set, after ordering by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b215dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bf2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(.75*len(merged_df))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df=merged_df.sort_values('Date')\n",
    "train_df,val_df=sorted_df[:train_size],sorted_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70451e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df),len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f29171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ebf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Date.min(),train_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.Date.min(),val_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_df.Date.min(),merged_test_df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fa672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093051e",
   "metadata": {},
   "source": [
    "### Input and Target columns\n",
    "\n",
    "Let's also identify input and target columns. Note that we can't use the no. of customers as an input, because this information isn't available beforehand. Also, we needn't use all the available columns, we can start out with just a small subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29249745",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols=['Store','DayOfWeek','Promo','StateHoliday','StoreType','Assortment','Day','Month','Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col='Sales'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172eeaf",
   "metadata": {},
   "source": [
    "Let's also separate out numeric and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[input_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=train_df[input_cols].copy()\n",
    "train_targets=train_df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs=val_df[input_cols].copy()\n",
    "val_targets=val_df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d18132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs=merged_test_df[input_cols].copy()\n",
    "# The test data doesn't have targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad3709",
   "metadata": {},
   "source": [
    "Note that some columns can be treated as both numeric and categorical, and it's up t you to decide how you want to deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=['Store','Day','Month','Year']\n",
    "categorical_cols=['DayOfWeek','Promo','StateHoliday','StoreType','Assortment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746f9f9",
   "metadata": {},
   "source": [
    "### Imputation, Scaling and Encode\n",
    "\n",
    "Let's impute missing data from numeric columns and scale the values to the $(0, 1)$ range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed05faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=SimpleImputer(strategy='mean').fit(train_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[numeric_cols]=imputer.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols]=imputer.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols]=imputer.transform(test_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6983eb7",
   "metadata": {},
   "source": [
    "Note that this step wasn't necessary for the store sales dataset, as there were no null values. Also, we can apply a different imputation strategy to different columns depending on their distributions (e.g. mean for normally distribute and median for exponentially distributed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd458eb",
   "metadata": {},
   "source": [
    "Let's also scale the values to the $(0, 1)$ range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2007e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler().fit(train_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[numeric_cols]=scaler.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols]=scaler.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols]=scaler.transform(test_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6e433",
   "metadata": {},
   "source": [
    "Finally, let's encode categorical columns as one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c39f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe79f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=OneHotEncoder(sparse_output=False,handle_unknown='ignore').fit(train_inputs[categorical_cols])\n",
    "encoded_cols=list(encoder.get_feature_names_out(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[encoded_cols]=encoder.transform(train_inputs[categorical_cols])\n",
    "val_inputs[encoded_cols]=encoder.transform(val_inputs[categorical_cols])\n",
    "test_inputs[encoded_cols]=encoder.transform(test_inputs[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84dd2c",
   "metadata": {},
   "source": [
    "Let's now extract out the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cffb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_inputs[numeric_cols+encoded_cols]\n",
    "X_val=val_inputs[numeric_cols+encoded_cols]\n",
    "X_test=test_inputs[numeric_cols+encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227657fd",
   "metadata": {},
   "source": [
    "## Step 5 - Create quick & easy baseline models to benchmark future models\n",
    "\n",
    "<img src=\"https://i.imgur.com/1DLgiEz.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542e23b",
   "metadata": {},
   "source": [
    "A quick baseline model helps establish the minimum score any ML model you train should achieve.\n",
    "\n",
    "\n",
    "### Fixed/Random Guess\n",
    "\n",
    "Let's define a model that always returns the mean value of Sales as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4741271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mean(inputs):\n",
    "    return np.full(len(inputs),merged_df.Sales.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds=return_mean(X_train)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f930a",
   "metadata": {},
   "source": [
    "Let's evaluate this to using the RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe98a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(train_preds,train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eee912",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(return_mean(X_val),val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fe62d",
   "metadata": {},
   "source": [
    "The model is off by about $3000 on average.\n",
    "\n",
    "Let's try another model, which makes a random guess between the lowest and highest sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_random(inputs):\n",
    "    lo,hi=merged_df.Sales.min(),merged_df.Sales.max()\n",
    "    return np.random.random(len(inputs))*(hi-lo)+lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3085e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds=guess_random(X_train)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(train_preds,train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(guess_random(X_val),val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e18ef8",
   "metadata": {},
   "source": [
    "Clearly, this model is much worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b01b42",
   "metadata": {},
   "source": [
    "### Baseline ML model\n",
    "\n",
    "Let's train a simple `LinearRegression` model, with no customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a15a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb36d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be89f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train,train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7da2e",
   "metadata": {},
   "source": [
    "`model.fit` uses the following workflow for training the model ([source](https://www.deepnetts.com/blog/from-basic-machine-learning-to-deep-learning-in-5-minutes.html)):\n",
    "\n",
    "1. We initialize a model with random parameters (weights & biases).\n",
    "2. We pass some inputs into the model to obtain predictions.\n",
    "3. We compare the model's predictions with the actual targets using the loss function.  \n",
    "4. We use an optimization technique (like least squares, gradient descent etc.) to reduce the loss by adjusting the weights & biases of the model\n",
    "5. We repeat steps 1 to 4 till the predictions from the model are good enough.\n",
    "\n",
    "\n",
    "<img src=\"https://www.deepnetts.com/blog/wp-content/uploads/2019/02/SupervisedLearning.png\" width=\"480\">\n",
    "\n",
    "The we have fit the model, the model can now be used to make predictions. Note that the parameters of the model will not be updated during prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65480828",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds=linreg.predict(X_train)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec06344",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(train_preds,train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds=linreg.predict(X_val)\n",
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(val_preds,val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd83f5",
   "metadata": {},
   "source": [
    "Note that a simple linear regression model isn't much better than our fixed baseline model which always predicts the mean.\n",
    "\n",
    "Based on the above baselines, we now know that any model we train should have ideally have a RMSE score lower than $2800. This baseline can also be conveyed to other stakeholders to get a sense of whether the range of loss makes sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5095c32",
   "metadata": {},
   "source": [
    "## Step 6 - Pick a strategy, train a model & tune hyperparameters\n",
    "\n",
    "<img src=\"https://i.imgur.com/aRuE5mw.png\" width=\"640\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cfba3",
   "metadata": {},
   "source": [
    "### Systematically Exploring Modeling Strategies\n",
    "\n",
    "Scikit-learn offers the following cheatsheet to decide which model to pick.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "\n",
    "Here's the general strategy to follow:\n",
    "\n",
    "- Find out which models are applicable to the problem you're solving.\n",
    "- Train a basic version for each type of model that's applicable\n",
    "- Identify the modeling approaches that work well and tune their hypeparameters\n",
    "- [Use a spreadsheet](Machine%20Learning%20Experiment%20Tracking.xlsx) to keep track of your experiments and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481ddc2",
   "metadata": {},
   "source": [
    "Let's define a function `try_model`, which takes a model, then performs training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(model):\n",
    "    # Fit the model\n",
    "    model.fit(X_train,train_targets)\n",
    "\n",
    "    # Generate predictions\n",
    "    train_preds=model.predict(X_train)\n",
    "    val_preds=model.predict(X_val)\n",
    "\n",
    "    # Compute RMSE\n",
    "    train_rmse=np.sqrt(mean_squared_error(train_targets,train_preds))\n",
    "    val_rmse=np.sqrt(mean_squared_error(val_targets,val_preds))\n",
    "    return train_rmse,val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3184e",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "\n",
    "Read about linear models here: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce68167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso,ElasticNet,SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_model(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_model(Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7359a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_model(Lasso())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d05f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_model(ElasticNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_model(SGDRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92805473",
   "metadata": {},
   "source": [
    "### Tree Based Models\n",
    "\n",
    "* Decision trees: https://scikit-learn.org/stable/modules/tree.html\n",
    "* Random forests and gradient boosting: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c923044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor,plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeRegressor(random_state=42)\n",
    "try_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "plot_tree(tree,max_depth=3,filled=True,feature_names=numeric_cols+encoded_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c133f",
   "metadata": {},
   "source": [
    "Let's try a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "try_model(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bac29c-2ec2-414f-817e-00c34ede9ea7",
   "metadata": {},
   "source": [
    "We've seen a significant reduction in the loss by using a random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e72315-e275-4e2c-8328-cad47884c063",
   "metadata": {},
   "source": [
    "## Step 7 - Experiment and combine results from multiple strategies\n",
    "\n",
    "<img src=\"https://i.imgur.com/ZqM6R8w.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae577d4c-0051-4655-bc3a-3f32bb8ecc69",
   "metadata": {},
   "source": [
    "In general, the following strategies can be used to improve the performance of a model:\n",
    "\n",
    "- Gather more data. A greater amount of data can let you learn more relationships and generalize the model better.\n",
    "- Include more features. The more relevant the features for predicting the target, the better the model gets.\n",
    "- Tune the hyperparameters of the model. Increase the capacity of the model while ensuring that it doesn't overfit.\n",
    "- Look at the specific examples where the model make incorrect or bad predictions and gather some insights\n",
    "- Try strategies like grid search for hyperparameter optimization and K-fold cross validation\n",
    "- Combine results from different types of models (ensembling), or train another model using their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e005dc-b81e-453a-a886-8175e83e93d0",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization & Grid Search\n",
    "\n",
    "You can tune hyperparameters manually, our use an automated tuning strategy like random search or Grid search. Follow this tutorial for hyperparameter tuning using Grid search: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "\n",
    "<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee078406-bb86-4958-adb4-7ee8e1e8d5ce",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation\n",
    "\n",
    "\n",
    "Here's what K-fold cross validation looks like visually ([source](https://vitalflux.com/k-fold-cross-validation-python-example/)):\n",
    "\n",
    "<img src=\"https://i.imgur.com/MxnzWwT.png\" width=\"480\">\n",
    "\n",
    "Follow this tutorial to apply K-fold cross validation: https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e9ba9-d272-4517-b796-6b75e52bc779",
   "metadata": {},
   "source": [
    "### Ensembling and Stacking\n",
    "\n",
    "Ensembling refers to combining the results of multiple models. Here's what ensembling looks like visually([source](https://www.kdnuggets.com/2019/01/ensemble-learning-5-main-approaches.html)):\n",
    "\n",
    "<img src=\"https://i.imgur.com/rrOKVEd.png\" width=\"480\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e79cdb-3310-40da-8f1e-82912ac57a92",
   "metadata": {},
   "source": [
    "Stacking is a more advanced version of ensembling, where we train another model using the results from multiple models. Here's what stacking looks like visually ([source](https://medium.com/ml-research-lab/stacking-ensemble-meta-algorithms-for-improve-predictions-f4b4cf3b9237)): \n",
    "\n",
    "<img src=\"https://i.imgur.com/VVzCWNB.png\" width=\"400\">\n",
    "\n",
    "Here's a tutorial on stacking: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50325f-d84d-4ab8-b6a6-82ae05e89a09",
   "metadata": {},
   "source": [
    "## Step 8 - Interpret models, study individual predictions & present your findings\n",
    "\n",
    "<img src=\"https://i.imgur.com/9axhOrA.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127278c-9f16-46f5-a83a-dfa874e478f8",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "You'll need to explain why your model returns a particular result. Most scikit-learn models offer some kind of \"feature importance\" score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedc3ca-7ae3-4a31-88f6-8e7395f0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5af1e-53d5-4243-8a99-196e00fc342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df=pd.DataFrame({\n",
    "    'feature':numeric_cols+encoded_cols,\n",
    "    'importance':rf.feature_importances_\n",
    "}).sort_values('importance',ascending=False)\n",
    "importance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b854384-ac8e-4773-b4ac-cb9da879c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=importance_df.head(10),x='importance',y='feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d5d74-9acf-4ed8-b29e-3d687d8e11dc",
   "metadata": {},
   "source": [
    "The above chart can be presented to non-technical stakeholders to explain how the model arrives at its result. For greater explainability, a single decision tree can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527f862-d96b-45e4-a864-733fe637a7ca",
   "metadata": {},
   "source": [
    "### Looking at individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b90fed-6606-426d-aced-0a06a38bee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input(model,single_input):\n",
    "    if single_input['Open']==0:\n",
    "        return 0\n",
    "    input_df=pd.DataFrame([single_input])\n",
    "    input_df['Date']=pd.to_datetime(input_df.Date)\n",
    "    input_df['Day']=input_df.Date.dt.day\n",
    "    input_df['Month']=input_df.Date.dt.month\n",
    "    input_df['Year']=input_df.Date.dt.year\n",
    "    input_df[numeric_cols]=imputer.transform(input_df[numeric_cols])\n",
    "    input_df[numeric_cols]=scaler.transform(input_df[numeric_cols])\n",
    "    input_df[encoded_cols]=encoder.transform(input_df[categorical_cols])\n",
    "    X_input=input_df[numeric_cols+encoded_cols]\n",
    "    pred=model.predict(X_input)[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007f733-fc24-4936-8bdd-723d6b91e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {'Id': 1,\n",
    " 'Store': 1,\n",
    " 'DayOfWeek': 4,\n",
    " 'Date': '2015-09-17 00:00:00',\n",
    " 'Open': 1.0,\n",
    " 'Promo': 1,\n",
    " 'StateHoliday': '0',\n",
    " 'SchoolHoliday': 0,\n",
    " 'StoreType': 'c',\n",
    " 'Assortment': 'a',\n",
    " 'CompetitionDistance': 1270.0,\n",
    " 'CompetitionOpenSinceMonth': 9.0,\n",
    " 'CompetitionOpenSinceYear': 2008.0,\n",
    " 'Promo2': 0,\n",
    " 'Promo2SinceWeek': np.nan,\n",
    " 'Promo2SinceYear': np.nan,\n",
    " 'PromoInterval': np.nan}\n",
    "\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce57350-223c-4021-bf6c-2ca11b880b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input(rf,sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466d425-cb05-424b-9fcd-bee79f15b381",
   "metadata": {},
   "source": [
    "Look at various examples from the training, validation and test sets to decide if you're happy with the result of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d4853-9089-4abb-89a8-003ea7af5b1f",
   "metadata": {},
   "source": [
    "### Presenting your results\n",
    "\n",
    "* Create a presentation for non-technical stakeholders\n",
    "* Understand your audience - figure out what they care about most\n",
    "* Avoid showing any code or technical jargon, include visualizations\n",
    "* Focus on metrics that are relevant for the business\n",
    "* Talk about feature importance and how to interpret results\n",
    "* Explain the strengths and limitations of the model\n",
    "* Explain how the model can be improved over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2d6f5-84c5-441e-9c46-efa0e5d04acb",
   "metadata": {},
   "source": [
    "### Making a submission on Kaggle\n",
    "\n",
    "If you're participating in a Kaggle competition, you can generate a submission CSV file and make a submission to check your score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210feda1-be14-402f-aa45-7eaf4d411c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=rf.predict(X_test)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591ae4f-1cfe-4341-a716-f0309849a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df=pd.read_csv('./rossmann-store-sales/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a1c9c-6d7b-4b39-8fa9-6873ac30b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['Sales']=test_preds*test_df['Open'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65703772-679e-450e-ae2c-c62e36bb8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa16204-149d-4785-8bea-e839b3d6531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f4671-66f0-49d6-9fe9-93a270b484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a5136-52a1-4689-a4bf-87710d65b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b580a58-62e6-447d-83c8-f1fb21cdce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c558fc-f493-4517-a4e9-90276bd1b972",
   "metadata": {},
   "source": [
    "You can now make a submission on this page: https://www.kaggle.com/c/rossmann-store-sales/submit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jskre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
